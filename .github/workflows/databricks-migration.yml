name: Databricks Migration Pipeline
on:
  push:
    branches:
      - master
  workflow_dispatch:

jobs:
  migration:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.x'

    - name: Set up Databricks profiles
      run: |
        echo "[KELLANOVA_WORKSPACE_SOURCE_NEW]" >> ~/.databrickscfg
        echo "host = https://dbc-f074b72b-99f1.cloud.databricks.com" >> ~/.databrickscfg
        echo "token = ${{ secrets.DATABRICKS_TOKEN_SOURCE }}" >> ~/.databrickscfg
        echo "[KELLANOVA_WORKSPACE_DESTINATION_NEW]" >> ~/.databrickscfg
        echo "host = https://dbtigeranalytics-ds-dev-dep.cloud.databricks.com" >> ~/.databrickscfg
        echo "token = ${{ secrets.DATABRICKS_TOKEN_DESTINATION }}" >> ~/.databrickscfg
        cat ~/.databrickscfg

    - name: Install dependencies
      run: |
        sudo apt update
        sudo apt install python3-pip
        pip3 install setuptools
        pip3 install deprecated
        python3 setup.py install

    - name: Run Databricks Migration Pipeline
      run: |
        SRC_PROFILE=KELLANOVA_WORKSPACE_SOURCE_NEW
        python3 migration_pipeline.py --profile $SRC_PROFILE --export-pipeline --use-checkpoint --session sample --set-export-dir ../backups/

    - name: Zip the backups folder
      run: |
        TIMESTAMP=$(date +"%Y-%m-%d_%H-%M-%S")
        zip -r backups_$TIMESTAMP.zip ../backups

    - name: Upload to S3
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_REGION: ${{ secrets.AWS_REGION }}
      run: |
        aws s3 cp backups_$TIMESTAMP.zip s3://existing-source-bucket-1/
