name: Databricks Migration Pipeline
on:
  push:
    branches:
      - master
  workflow_dispatch:

jobs:
  migration:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.x'

    - name: Set up Databricks profiles
      run: |
        echo "[KELLANOVA_WORKSPACE_SOURCE_NEW]" >> ~/.databrickscfg
        echo "host = https://dbc-f074b72b-99f1.cloud.databricks.com" >> ~/.databrickscfg
        echo "token = ${{ secrets.DATABRICKS_TOKEN_SOURCE }}" >> ~/.databrickscfg
        echo "[KELLANOVA_WORKSPACE_DESTINATION_NEW]" >> ~/.databrickscfg
        echo "host = https://dbc-280cb907-6a02.cloud.databricks.com" >> ~/.databrickscfg
        echo "token = ${{ secrets.DATABRICKS_TOKEN_DESTINATION }}" >> ~/.databrickscfg
        cat ~/.databrickscfg

    - name: Install dependencies
      run: |
        sudo apt update
        sudo apt install python3-pip
        pip3 install setuptools
        pip3 install deprecated
        python3 setup.py install

    - name: Run Databricks Migration Pipeline
      run: |
        SRC_PROFILE=KELLANOVA_WORKSPACE_SOURCE_NEW
        python3 migration_pipeline.py --profile $SRC_PROFILE --export-pipeline --use-checkpoint --session sample --set-export-dir ../backups/
        

    - name: Zip the backups folder
      run: |
        zip -r backups_123.zip ../backups

    - name: Validate zip file
      id: validate_zip
      run: |
        if unzip -t backups_123.zip; then
          echo "Valid zip file"
          echo "zip_valid=true" >> $GITHUB_ENV
        else
          echo "Invalid zip file, skipping upload."
          echo "zip_valid=false" >> $GITHUB_ENV
        fi
        

    - name: Upload to S3
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_REGION: ${{ secrets.AWS_REGION }}
      run: |
        aws s3 cp backups_123.zip s3://existing-source-bucket-1/


    - name: Unzip backups folder
      run: |
        unzip backups_123.zip -d ../

    - name: Run Databricks Migration Import Pipeline
      run: |
        DEST_PROFILE=KELLANOVA_WORKSPACE_DESTINATION_NEW
        python3 migration_pipeline.py --profile $DEST_PROFILE --import-pipeline --use-checkpoint --session sample


